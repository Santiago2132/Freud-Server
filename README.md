# ğŸ§  Freudâ€‘Server

**ConversaciÃ³n inteligente con IA local para evaluaciÃ³n psicolÃ³gica indirecta.**

Este proyecto es un servidor de chat impulsado por modelos de lenguaje alojados localmente con [Ollama](https://ollama.com/), diseÃ±ado para evaluar a una persona psicolÃ³gicamente durante una conversaciÃ³n natural de 5 minutos. Todo funciona sin conexiÃ³n a internet, sin uso de APIs externas, 100% en tu mÃ¡quina.

---

## ğŸ¯ Objetivo

> Evaluar de forma indirecta el estado emocional y psicolÃ³gico de una persona a travÃ©s de una conversaciÃ³n guiada de 5 minutos con una IA.

Este sistema simula una conversaciÃ³n fluida y natural, capturando el contexto reciente y utilizando un **prompt psicolÃ³gico especializado** para detectar rasgos emocionales, estados mentales y reacciones, sin preguntas invasivas.

---

## ğŸš€ CaracterÃ­sticas

- âœ… **IA local (offline)** â€“ Potenciada por Ollama y modelos como LLaMA3, Mistral, etc.
- ğŸ§  **Memoria de 5 minutos** â€“ La IA solo recuerda lo conversado en los Ãºltimos 5 minutos, simulando enfoque clÃ­nico.
- ğŸ§¬ **Prompt psicolÃ³gico** â€“ DiseÃ±ado para generar respuestas que permiten evaluar personalidad y emociones indirectamente.
- ğŸ“¦ **Modular y Extensible** â€“ Puedes convertir este motor en una IA multipropÃ³sito.
- ğŸ“ˆ **TensorFlow ready** â€“ Incluye espacio para aÃ±adir anÃ¡lisis de sentimiento y patrones psicolÃ³gicos con Machine Learning.

---

## ğŸ› ï¸ TecnologÃ­as

- ğŸ Python 3.11+
- ğŸ” Ollama (para ejecutar modelos LLM locales)
- ğŸ§  Modelos LLaMA3, Mistral o similares
- ğŸ§® TensorFlow (opcional, para anÃ¡lisis de respuestas)
- ğŸ—ƒï¸ JSON (para el historial en memoria)

---

## ğŸ“¦ InstalaciÃ³n

```bash
# Clona el repositorio
git clone https://github.com/tuusuario/freud-server.git
cd freud-server

# Instala dependencias de Python
pip install -r requirements.txt

# Descarga el modelo local (ejemplo con LLaMA3)
ollama pull llama3

# Inicia el servidor de Ollama
ollama serve
